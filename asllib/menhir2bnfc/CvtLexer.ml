(******************************************************************************)
(*                                ASLRef                                      *)
(******************************************************************************)
(*
 * SPDX-FileCopyrightText: Copyright 2022-2023 Arm Limited and/or its affiliates <open-source-office@arm.com>
 * SPDX-License-Identifier: BSD-3-Clause
 *)
(******************************************************************************)
(* Disclaimer:                                                                *)
(* This material covers both ASLv0 (viz, the existing ASL pseudocode language *)
(* which appears in the Arm Architecture Reference Manual) and ASLv1, a new,  *)
(* experimental, and as yet unreleased version of ASL.                        *)
(* This material is work in progress, more precisely at pre-Alpha quality as  *)
(* per Arm’s quality standards.                                               *)
(* In particular, this means that it would be premature to base any           *)
(* production tool development on this material.                              *)
(* However, any feedback, question, query and feature request would be most   *)
(* welcome; those can be sent to Arm’s Architecture Formal Team Lead          *)
(* Jade Alglave <jade.alglave@arm.com>, or by raising issues or PRs to the    *)
(* herdtools7 github repository.                                              *)
(******************************************************************************)

(*
   Translate an ocamllex .ml file to a set of bnfc tokens and comment descriptors
 *)

open Ppxlib
open BNFC
open Utils

type lex_case = {
  pat : Regex.t;
  last_action : string option;
  is_lookahead : bool;
  result : string;
}

type lex_function =
  | LexTransform of string
      (** A basic fn(a) -> b transform - these usually just construct tokens.
        E.g. let mk_integer a = INTEGER (int_of_string a)

        This structure contains the lex result as string *)
  | LexMapping of Regex.t StringMap.t
      (** A function of the form fn(a) -> match a with ... -> b
        E.g. keyword maps: match a with | "for" -> FOR | "while" -> WHILE ...

        This structure maps each pattern in the pattern match to its lex result as string *)
  | LexNextChar of lex_case list
      (** A function of the form fn(a, last_action, ..) -> let next_char = ... in match next_char with ...
        These are autogenerated as lex states by ocamllex

        This structure describes every possible outcome of the lexer's next character checks.
        Mapping each effective regex and current last_action to be performed to a lex result as string*)
  | LexResult of (lex_case list * string StringMap.t)
      (** A function of the form fn(a, last_action, ..) -> let ocaml_lex_result = <NextChar> in match ocaml_lex_result with 0 -> res1 | 1 -> res2 ...
        These are autogenerated as lex states by ocamllex

        This structure describes a tuple where:
            * The first element is the same as NextChar
            * The second eleemnt is a mapping between the parse results in the first element
              to a parse result of the calling function (or top level) *)

(* A helper function for printing the simplified ast's regex -> result mapping structures *)
let string_of_lex_case { pat; last_action; is_lookahead; result } =
  match last_action with
  | Some action ->
      Printf.sprintf "(%s, %s, %s) -> %s"
        (Regex.string_of_regex pat)
        action
        (string_of_bool is_lookahead)
        result
  | None ->
      Printf.sprintf "(%s, _, %s) -> %s"
        (Regex.string_of_regex pat)
        (string_of_bool is_lookahead)
        result

(* A helper function to print the lex_function structures *)
let string_of_lex_function (lex_fn : lex_function) : string =
  let mk_next_char ls = List.map string_of_lex_case ls |> String.concat "\n" in
  match lex_fn with
  | LexTransform s -> s
  | LexMapping ls ->
      StringMap.fold
        (fun res t acc ->
          Printf.sprintf "%s -> %s" (Regex.string_of_regex t) res :: acc)
        ls []
      |> String.concat "\n"
  | LexNextChar ls -> mk_next_char ls
  | LexResult (ls, res) ->
      mk_next_char ls ^ "\n\n"
      ^ (List.map
           (fun (k, v) -> Printf.sprintf "%s -> %s" k v)
           (StringMap.bindings res)
        |> String.concat "\n")

(* A utility function to convert a token name into a valid bnfc identifier *)
let slug_str =
  String.map (function
    | ('A' .. 'Z' | 'a' .. 'z' | '0' .. '9' | '_') as c -> c
    | _ -> '_')

module type Config = sig
  val filename : string
end

(* Extract token and comemnt data from an ocamllex -ml file. *)
module Convert (Config : Config) : sig
  val comments : comment list
  val tokens : token list
  val reserved : decl list
end = struct
  open Pprintast
  open Regex

  let load_lexer chan = Lexing.from_channel chan |> Parse.implementation
  let lex_data = Utils.with_open_in_bin Config.filename load_lexer

  (* Constants pointing to various autogenerated ocamllex variable names *)
  let lex_entry_point_name = "token"
  let lex_next_char_name = "next_char"
  let lex_last_action_name = "_last_action"
  let lex_current = "_curr"
  let lex_last = "_last"
  let lex_result_name = "__ocaml_lex_result"
  let lex_refill_buf = "__ocaml_lex_refill_buf"

  (* Used to identify failure states *)
  let lex_raise_name = "raise"

  (*
    OCaml AST tranversal to construct lex_function objects.
  *)

  (* Gather the top level declarations from the `ocamllex -ml` file *)
  let rec build_name_to_code_map acc code_struct =
    let get_pat_name pat =
      match pat.ppat_desc with
      | Ppat_var { txt } -> txt
      | _ ->
          raise
            (Failure
               "Unsupported AST pattern when converting Lexer into tokens.")
    in
    match code_struct.pstr_desc with
    | Pstr_value (_, value_binding_list) ->
        (* Note: We drop any function args here.
           This approach assumes that the lexer is fairly simple and the args are fairly consistent.
           Namely we assume:
              * All user defined function are not stateful
              * All ocamllex generated functions pass last_action around *)
        let get_val_binding_data acc { pvb_pat = pat; pvb_expr = expr } =
          let pat_name = get_pat_name pat in
          if pat_name = lex_refill_buf then acc
          else StringMap.add pat_name expr acc
        in
        List.fold_left get_val_binding_data acc value_binding_list
    | Pstr_module
        {
          pmb_expr =
            {
              pmod_desc =
                Pmod_functor (_, { pmod_desc = Pmod_structure structure });
            };
        } ->
        List.fold_left build_name_to_code_map acc structure
    | Pstr_open _ | Pstr_exception _ | Pstr_modtype _ -> acc
    | _ ->
        let struct_str = string_of_structure [ code_struct ] in
        let err_msg =
          Printf.sprintf
            "Unexpected structure type when converting Lexer into tokens for \
             structure:\n\
             %s"
            struct_str
        in
        raise (Failure err_msg)

  let struct_map : expression StringMap.t =
    List.fold_left build_name_to_code_map StringMap.empty lex_data

  (* Utility function to get the effective return of an expression *)
  let rec get_last_expr expr =
    match expr.pexp_desc with
    | Pexp_fun (_, None, _, sub_expr)
    | Pexp_function [ { pc_rhs = sub_expr } ]
    | Pexp_let (_, _, sub_expr)
    (* We only care about the return statement - or the last expr in the sequence *)
    | Pexp_sequence (_, sub_expr) ->
        get_last_expr sub_expr
    | _ -> expr

  (* A utility function to get the effective return value
     of a given expression as string.
     This could be:
         * The name of a constructor
         * The name of a variable
         * A function call
            * |> is treated such that the last function called is returned (rhs)
            * @@ is treated such that the first function called is returned (lhs)
  *)
  let rec get_last_expr_str (expr : expression) : string =
    match expr.pexp_desc with
    (* Handle nested functions *)
    | Pexp_apply
        ({ pexp_desc = Pexp_ident { txt = Lident "|>" } }, [ _; (_, expr) ])
    | Pexp_apply
        ({ pexp_desc = Pexp_ident { txt = Lident "@@" } }, [ (_, expr); _ ]) ->
        get_last_expr_str expr
    | Pexp_apply ({ pexp_desc = Pexp_ident { txt = lident } }, _)
    | Pexp_construct ({ txt = lident }, _)
    | Pexp_ident { txt = lident } ->
        Longident.flatten_exn lident |> String.concat "."
    | Pexp_constant (Pconst_integer (id, _)) -> id
    | _ ->
        Printf.printf "%s\n" (string_of_expression expr);
        raise (Failure "Unexpected expression.")

  (* A utility function to extract (string * string) list mappings
     from an ocaml_lex_result match statement
     where the first string is the integer result and the second string
     is the actual lexing result *)
  let get_lex_result_map (expr : expression) : string StringMap.t =
    match expr.pexp_desc with
    | Pexp_match ({ pexp_desc = Pexp_ident { txt = Lident id } }, case_list)
      when id = lex_result_name ->
        let case_to_map acc case =
          match case with
          | {
           pc_lhs =
             { ppat_desc = Ppat_constant (Pconst_integer (int_key, None)) };
           pc_guard = None;
           pc_rhs;
          } ->
              let value = get_last_expr pc_rhs |> get_last_expr_str in
              StringMap.add int_key value acc
          | { pc_lhs = { ppat_desc = Ppat_any }; pc_guard = None; pc_rhs } ->
              let value = get_last_expr pc_rhs |> get_last_expr_str in
              StringMap.add "_" value acc
          | _ ->
              raise
                (Failure "lex_result map can only map integers to expressions")
        in
        List.fold_left case_to_map StringMap.empty case_list
    | _ ->
        Printf.printf "Invalid lex_result match statement:\n%s\n"
          (string_of_expression expr);
        raise @@ Failure "Expected a lex_result_table"

  (* A utility function used to extract ocaml_lex_result let expressions *)
  let rec get_lex_result (expr : expression) : expression option =
    match expr.pexp_desc with
    | Pexp_function [ { pc_rhs = e } ] | Pexp_fun (_, None, _, e) ->
        get_lex_result e
    | Pexp_let
        (_, [ { pvb_pat = { ppat_desc = Ppat_var { txt } }; pvb_expr } ], _)
      when String.equal txt lex_result_name ->
        Some (get_last_expr pvb_expr)
    | _ -> None

  (* A utility function to extract a _last_action variable
     assignment from a function block. *)
  let rec get_let_assignment expr target_name =
    match expr.pexp_desc with
    | Pexp_let
        ( _,
          [
            {
              pvb_pat = { ppat_desc = Ppat_var { txt } };
              pvb_expr = { pexp_desc = Pexp_constant (Pconst_integer (id, _)) };
            };
          ],
          _ )
      when txt = target_name ->
        Some id
    | Pexp_let
        ( _,
          [
            {
              pvb_pat = { ppat_desc = Ppat_var { txt } };
              pvb_expr = { pexp_desc = Pexp_ident { txt = Lident rhs } };
            };
          ],
          _ )
      when txt = target_name ->
        Some rhs
    | Pexp_let (_, _, subexpr)
    | Pexp_function [ { pc_rhs = subexpr } ]
    | Pexp_fun (_, None, _, subexpr) ->
        get_let_assignment subexpr target_name
    | _ -> None

  (* Create a (regex, expression) map from each structure *)
  (* TODO: Possibly unnecessary for our use-case, but last_action can be specified as an integer function argument as well
           Such an argument overrides prior last_action state *)
  let rec get_next_char ?last_action ?regex_acc (expr : expression) :
      lex_case list =
    match expr.pexp_desc with
    | Pexp_match (_, case_list) ->
        let mk_oneof t1 t2 =
          match (t1, t2) with
          | Some (Char c1), Some (Char c2) ->
              Some (OneOf ([ c1; c2 ] |> List.to_seq |> String.of_seq))
          | Some (OneOf s), Some (Char c2) ->
              Some (OneOf (s ^ String.make 1 c2))
          | None, Some c | Some c, None -> Some c
          | _ -> Some (Choice [ [ Option.get t1 ]; [ Option.get t2 ] ])
        in
        let rec resolve_regex { ppat_desc } =
          match ppat_desc with
          | Ppat_any -> Some MatchAll
          | Ppat_constant (Pconst_integer (chr, None)) ->
              let res =
                match chr with
                | "256" -> None (* Ignore EOF *)
                | _ -> Some (Char (int_of_string chr |> Char.chr))
              in
              res
          | Ppat_or (p1, p2) ->
              let t1 = resolve_regex p1 in
              let t2 = resolve_regex p2 in
              let res = mk_oneof t1 t2 in
              res
          | _ -> raise (Failure "Unsupported pattern in match stetement.")
        in
        let mk_regex_seq regex_acc regex =
          match (List.rev regex_acc, regex) with
          | Char c1 :: rest, Char c2 ->
              Str ([ c1; c2 ] |> List.to_seq |> String.of_seq) :: rest
              |> List.rev
          | Str s :: rest, Char c ->
              Str (s ^ String.make 1 c) :: rest |> List.rev
          | _ -> regex_acc @ [ regex ]
        in
        let resolve_case (regex, case) =
          match case with
          | { pc_guard = None; pc_rhs } ->
              let last = get_last_expr pc_rhs in
              let mk_regex_acc regex =
                match regex_acc with
                | Some acc -> mk_regex_seq acc regex
                | None -> [ regex ]
              in
              let res =
                if Option.is_none regex then []
                else
                  let regex = Option.get regex in
                  match last.pexp_desc with
                  | Pexp_match _ ->
                      let regex_acc = mk_regex_acc regex in
                      let new_last_action =
                        get_let_assignment pc_rhs lex_last_action_name
                      in
                      let is_final_regex = Option.is_some new_last_action in
                      let last_action =
                        if is_final_regex then new_last_action else last_action
                      in
                      let is_lookahead =
                        get_let_assignment pc_rhs lex_current = Some lex_last
                      in
                      if is_final_regex then
                        let result = Option.get last_action in
                        { pat = regex_acc; last_action; is_lookahead; result }
                        :: get_next_char ?last_action ~regex_acc last
                      else get_next_char ?last_action ~regex_acc last
                  | _ ->
                      let result = last |> get_last_expr_str in
                      let is_lookahead =
                        get_let_assignment pc_rhs lex_current = Some lex_last
                      in
                      let regex_acc = mk_regex_acc regex in
                      [ { pat = regex_acc; last_action; is_lookahead; result } ]
              in
              res
          | _ ->
              raise
                (Failure
                   "Guarded case expressions for next_char sections is \
                    unsuppported.")
        in
        let regex_to_case =
          let get_regex { pc_lhs } = resolve_regex pc_lhs in
          let result = List.map (fun c -> (get_regex c, c)) case_list in
          let rev_res = List.rev result in
          match List.hd rev_res with
          | Some MatchAll, c -> (
              let res_tl = List.tl rev_res |> List.rev in
              let other_chars =
                List.fold_left mk_oneof None
                @@ List.filter_map (fun t -> Some (fst t)) res_tl
              in
              match other_chars with
              | Some other -> res_tl @ [ (Some (Except (MatchAll, other)), c) ]
              | None -> result)
          | _ -> result
        in
        List.map resolve_case regex_to_case |> List.concat
    | _ -> raise (Failure "expr must be a match statemnet")

  let get_lex_result_struct (expr : expression) :
      lex_case list * string StringMap.t =
    let last_action = get_let_assignment expr lex_last_action_name in
    let result_map = get_lex_result_map (get_last_expr expr) in
    let next_char =
      match get_lex_result expr with
      | Some e -> get_next_char ?last_action e
      | None -> assert false
    in
    (next_char, result_map)

  let get_lex_mapping (expr : expression) : Regex.t StringMap.t =
    let rec pat_to_tok pat =
      match pat.ppat_desc with
      | Ppat_constant (Pconst_string (s, _, _)) -> Str s
      | Ppat_or (p1, p2) -> (
          let t1 = pat_to_tok p1 in
          let t2 = pat_to_tok p2 in
          match (t1, t2) with
          | Choice c, Str _ -> Choice (c @ [ [ t2 ] ])
          | _ -> Choice [ [ t1 ]; [ t2 ] ])
      | Ppat_var _ -> MatchAll
      | Ppat_any -> MatchAll
      | _ ->
          raise
            (Failure
               "String pattern matching must have the patterns be strings or | \
                patterns.")
    in
    let map_case case =
      match case with
      | {
       pc_lhs;
       pc_guard = None;
       pc_rhs =
         { pexp_desc = Pexp_construct _ | Pexp_ident _ | Pexp_apply _ } as
         pc_rhs;
      } ->
          Some ([ pat_to_tok pc_lhs ], get_last_expr_str pc_rhs)
      (* TODO Thess are reserved complex tokens and backwards compatibility tokens
         They likely want to be handled in the future *)
      | { pc_guard; pc_rhs } ->
          Printf.printf
            "Warning: Skipping the following structure from the keyword map:\n\
             ? %s -> %s\n"
            (if Option.is_some pc_guard then
               "when " ^ (string_of_expression @@ Option.get pc_guard) ^ " "
             else "")
            (string_of_expression pc_rhs);
          None
    in
    match expr.pexp_desc with
    | Pexp_match
        ( _,
          ({
             pc_lhs = { ppat_desc = Ppat_constant (Pconst_string _) };
             pc_guard = None;
           }
           :: _ as case_list) ) ->
        let case_list = List.filter_map map_case case_list in
        List.fold_left
          (fun acc (re, name) ->
            StringMap.update name
              (fun opt_re ->
                match opt_re with
                | None -> Some re
                | Some re2 -> Some [ Choice [ re; re2 ] ])
              acc)
          StringMap.empty case_list
    | _ -> assert false

  (* Translate the ocaml ast structures to lex_function structures *)
  let translate_code (struct_map : expression StringMap.t) :
      lex_function StringMap.t =
    let expr_to_lex_func expr =
      let last_expr = get_last_expr expr in
      match last_expr.pexp_desc with
      | Pexp_ident _ | Pexp_construct _ | Pexp_apply _ ->
          LexTransform (get_last_expr_str last_expr)
      | Pexp_match ({ pexp_desc = Pexp_ident { txt = Lident id } }, _)
        when id = lex_next_char_name ->
          let last_action = get_let_assignment expr lex_last_action_name in
          LexNextChar (get_next_char ?last_action last_expr)
      | Pexp_match ({ pexp_desc = Pexp_ident { txt = Lident id } }, _)
        when id = lex_result_name ->
          LexResult (get_lex_result_struct expr)
      | Pexp_match _ -> LexMapping (get_lex_mapping last_expr)
      | _ ->
          Printf.printf "Cannot determine lex function type for:\n%s\n"
          @@ string_of_expression expr;
          raise @@ Failure "Unsupported"
    in
    StringMap.map expr_to_lex_func struct_map

  (* Transform the ocaml ast to a simpler structure *)
  let lexer_data : lex_function StringMap.t = translate_code struct_map

  (*
     Transform the extracted data from the lexer into a sequence of tokens and comments
   *)

  (* HACK: We track parse results as strings. In complex cases these can be arbitrary function calls.
     In our use-case we only use a custom Error module to call the raise function indirectly.
     To make sure all failure states are accounted for - we rename the Error.<fn> call to raise. *)
  let lexer_data =
    let rename res =
      let lident_parts = Longident.parse res |> Longident.flatten_exn in
      if List.hd lident_parts = "Error" && List.length lident_parts > 1 then
        lex_raise_name
      else res
    in
    let fix_raise fn =
      match fn with
      | LexTransform res -> LexTransform (rename res)
      | LexMapping mappings ->
          let updated =
            StringMap.fold
              (fun res t acc ->
                StringMap.update (rename res)
                  (fun opt_t ->
                    match opt_t with
                    | None -> Some t
                    | Some other_t -> Some [ Choice [ t; other_t ] ])
                  acc)
              mappings StringMap.empty
          in
          LexMapping updated
      | LexNextChar cases ->
          let new_cases =
            List.map
              (fun { pat; last_action; is_lookahead; result } ->
                { pat; last_action; is_lookahead; result = rename result })
              cases
          in
          LexNextChar new_cases
      | LexResult (cases, result_map) ->
          let new_result_map = StringMap.map rename result_map in
          LexResult (cases, new_result_map)
    in
    StringMap.map fix_raise lexer_data

  (*
     Split off keywords and reserved tokens.
     We assume these are stored in a keyword table converted to the format of a LexMapping
     *)
  let reserved_decls, keyword_bnfc, lexer_data =
    let keyword_maps, rest =
      StringMap.partition
        (fun _ map -> match map with LexMapping _ -> true | _ -> false)
        lexer_data
    in
    let reserved_name = "ReservedKeyword" in
    let rec flatten_reserved regex =
      let name = reserved_name in
      match regex with
      | [ Str s ] ->
          let ast_name = reserved_name ^ "_" ^ slug_str s in
          [ Decl { ast_name; name; terms = [ Literal s ] } ]
      | [ Char c ] ->
          let s = String.make 1 c in
          let ast_name = reserved_name ^ "_" ^ slug_str s in
          [ Decl { ast_name; name; terms = [ Literal s ] } ]
      | [ Choice choices ] -> List.map flatten_reserved choices |> List.flatten
      | _ -> assert false (* Unsupported *)
    in
    let reserved_decls, keywords, rest =
      StringMap.fold
        (fun name def acc ->
          match def with
          | LexMapping maps ->
              StringMap.fold
                (fun result regex (reserved, keywords, rest) ->
                  let final_result =
                    match StringMap.find_opt result lexer_data with
                    | None -> result
                    | Some (LexTransform t) -> t
                    | _ -> assert false (* Unsupported *)
                  in
                  let is_matchall =
                    match regex with [ MatchAll ] -> true | _ -> false
                  in
                  if String.equal final_result lex_raise_name then
                    (* Handle Reserved *)
                    let reserved = reserved @ flatten_reserved regex in
                    (reserved, keywords, rest)
                  else if not @@ is_matchall then
                    (* Handle Keyword *)
                    let new_kw = Token { name = final_result; regex } in
                    (reserved, new_kw :: keywords, rest)
                  else
                    (* Handle MatchAll case, by adding it as a transform to *)
                    (* Verify that only one catch-all case exists  *)
                    let () = assert (not @@ StringMap.mem name rest) in
                    let rest =
                      StringMap.add name (LexTransform final_result) rest
                    in
                    (reserved, keywords, rest))
                maps acc
          | _ -> assert false (* Partitioned, unreachable *))
        keyword_maps ([], [], rest)
    in
    (reserved_decls, keywords, rest)

  (* A utility function to convert a lex_case into a (token * string) list mapping *)
  let rec flatten_case result_map last_action_opt visited
      { pat; last_action; is_lookahead; result } =
    let last_action =
      match last_action with None -> last_action_opt | Some _ -> last_action
    in
    let actual_result =
      let res =
        if result = lex_last_action_name then
          (* If there is no last_action specified - go to the catch - all case of the result_map *)
          match last_action with
          | None -> StringMap.find "_" result_map
          | Some r -> r
        else result
      in
      match StringMap.find_opt res result_map with None -> res | Some r -> r
    in
    let merge_reference flattened =
      let rec_pattern, rest =
        List.partition (fun (_, r, _) -> r = actual_result) flattened
      in
      let rec_pattern = List.filter (fun (_, _, l) -> not l) rec_pattern in
      let rec_prefix =
        if List.length rec_pattern = 0 then []
        else if List.length rec_pattern = 1 then
          [ ZeroOrMore (List.hd rec_pattern |> fun (t, _, _) -> t) ]
        else
          [ ZeroOrMore [ Choice (List.map (fun (t, _, _) -> t) rec_pattern) ] ]
      in
      let rest =
        List.filter (fun (_, r, _) -> not @@ String.equal r lex_raise_name) rest
      in
      let () =
        (* Sanity check - all recursive nodes must have a terminal case *)
        assert (List.length rest != 0)
      in
      List.map
        (fun (p, r, l) ->
          if l then (pat @ rec_prefix, r, false)
          else (pat @ rec_prefix @ p, r, false))
        rest
    in
    (* If _last_action is returned assume this is a lookahead and ignore it *)
    if result = lex_last_action_name then []
      (* Recursive rule, we return it for now. A ZeroOrMore/OneOrMore should be created *)
    else if List.exists (String.equal actual_result) visited then
      [ (pat, actual_result, is_lookahead) ]
    else
      match StringMap.find_opt actual_result lexer_data with
      (* Handle terminal states *)
      | None -> [ (pat, actual_result, is_lookahead) ]
      | Some (LexTransform t) -> [ (pat, t, is_lookahead) ]
      | Some (LexMapping _) -> assert false (* Handled as keywords *)
      (* Handle non-terminal states *)
      | Some (LexNextChar lex_case) ->
          let flattened =
            List.map
              (flatten_case result_map last_action (actual_result :: visited))
              lex_case
            |> List.flatten
          in
          merge_reference flattened
      | Some (LexResult (lex_case, new_result_map)) ->
          let update_res res =
            match StringMap.find_opt res result_map with
            | None -> res
            | Some r -> r
          in
          let new_result_map = StringMap.map update_res new_result_map in
          let flattened =
            List.map
              (flatten_case new_result_map last_action (actual_result :: visited))
              lex_case
            |> List.flatten
          in
          merge_reference flattened

  (* Explore the token function in the lexer and build regexes per token *)
  let flat_lexer_data : (Regex.t * string) list =
    let entry_point = StringMap.find lex_entry_point_name lexer_data in
    match entry_point with
    | LexResult (cases, result_map) ->
        List.map (flatten_case result_map None [ lex_entry_point_name ]) cases
        |> List.flatten
        |> List.filter_map (function
             | re, result, false when not @@ String.equal result lex_raise_name
               ->
                 Some (re, result)
             | _ -> None)
    | _ ->
        let msg =
          Printf.sprintf
            "The lexer entry point must be a function called %s which contains \
             a %s definition."
            lex_entry_point_name lex_result_name
        in
        raise @@ Failure msg

  (*
     The following functions simplify the regex data to make it more readable
  *)

  (* If a choice exists of the form:
      ('a'|'b'|(char - ["ab"])) simplify to `char`
     In other words, if a choice has an exclude directive which excludes all other choices, we keep the base
     symbol before the exclusion *)
  let compress_choice choices =
    let except, rest =
      List.partition
        (function [ Except (_, OneOf _) ] -> true | _ -> false)
        choices
    in
    if
      List.length except = 1
      && List.for_all (function [ Char _ ] -> true | _ -> false) rest
    then
      let chars =
        List.map (function [ Char c ] -> c | _ -> assert false) rest
        |> List.sort Char.compare |> List.to_seq |> String.of_seq
      in
      let except_sym, except_chars =
        match List.hd except with
        | [ Except (sym, OneOf chars) ] -> (sym, chars)
        | _ -> assert false
      in
      if chars = except_chars then except_sym else Choice choices
    else Choice choices

  (* If the following pattern exists:
      "sym" ("sym")* - simplify to ("sym")+
  *)
  let rec compress_regex regex =
    match regex with
    | [] -> []
    | Char c1 :: Char c2 :: rest ->
        compress_regex @@ (Str (Printf.sprintf "%c%c" c1 c2) :: rest)
    | Str s :: Char c :: rest ->
        compress_regex @@ (Str (Printf.sprintf "%s%c" s c) :: rest)
    | Char c :: Str s :: rest ->
        compress_regex @@ (Str (Printf.sprintf "%c%s" c s) :: rest)
    | el :: ZeroOrMore el2 :: rest when [ el ] = el2 ->
        compress_regex @@ (OneOrMore el2 :: rest)
    (* Propagate kleene star into choices *)
    | ZeroOrMore [ Choice c ] :: r ->
        let new_c =
          List.map
            (function [ ZeroOrMore t ] | [ OneOrMore t ] | t -> t)
            (List.map compress_regex c)
        in
        ZeroOrMore (compress_regex [ Choice new_c ]) :: compress_regex r
    | ZeroOrMore c :: r -> ZeroOrMore (compress_regex c) :: compress_regex r
    | OneOrMore c :: r -> OneOrMore (compress_regex c) :: compress_regex r
    | Choice c :: r ->
        let new_choice = compress_choice (List.map compress_regex c) in
        new_choice :: compress_regex r
    | h :: t -> h :: compress_regex t

  (* This function sorts the string contents of OneOf statemetns
     such as ["cba"] -> ["abc"] to make consistent comparisons *)
  let rec order_one_of regex =
    let rec order_oo re =
      match re with
      | OneOf s ->
          OneOf
            (String.to_seq s |> List.of_seq |> List.sort Char.compare
           |> List.to_seq |> String.of_seq)
      | ZeroOrMore t -> ZeroOrMore (order_one_of t)
      | OneOrMore t -> OneOrMore (order_one_of t)
      (* Note: Choices should likely also be sorted, but it is not an immediate requirement *)
      | Choice t -> Choice (List.map order_one_of t)
      | Except (l, r) -> Except (order_oo l, order_oo r)
      | _ -> re
    in
    List.map order_oo regex

  let simplify_token token = order_one_of token |> compress_regex

  (*
     Extract comments and remaining tokens

     All comments recursively call the lexer entrypoint to fetch the next token.
     BNFC ignores whitespace by default so we also ignore whitespace.

     We identify a single line comment by as a regex starting with a string or char and ending with a newline
     E.g. "//" char* \n

     We identify a multiline comment by a sequence starting and ending with a string or char permitting
     zero or more arbitrary charachers between them.
     E.g. "/*" char* "*/"
    *)

  let (comment_bnfc, regex_bnfc) : comment list * token list =
    let rec collect_unique_results rem_lexer_data =
      match rem_lexer_data with
      | [] -> []
      | (_, res) :: _ ->
          let same_res, rest =
            List.partition (fun (_, r) -> String.equal r res) rem_lexer_data
          in
          let new_tok_mapping =
            match same_res with
            | t :: [] -> t
            | _ -> ([ Choice (List.map fst same_res) ], res)
          in
          new_tok_mapping :: collect_unique_results rest
    in
    let flat_lexer_data =
      List.map (fun (t, r) -> (simplify_token t, r)) flat_lexer_data
    in
    let comment_mappings, rest =
      List.partition
        (fun (_, res) -> String.equal res lex_entry_point_name)
        flat_lexer_data
    in
    let comment_bnfc =
      (* BNFC ignores newlines and whitespace by default *)
      let comments =
        let module CharSet = Set.Make (Char) in
        let ws_chars = CharSet.of_list [ '\n'; '\r'; ' '; '\t' ] in
        List.filter
          (fun (t, _) ->
            match t with
            | [ Char c ] -> not @@ CharSet.mem c ws_chars
            | [ OneOf s ] | [ OneOrMore [ OneOf s ] ] ->
                not @@ String.for_all (fun c -> CharSet.mem c ws_chars) s
            | _ -> true)
          comment_mappings
      in
      let mk_comment_bnfc (tok, _) =
        match tok with
        | [ Str s; ZeroOrMore [ Except (MatchAll, Char '\n') ] ] ->
            Comment [ s ]
        | [ Str s; ZeroOrMore [ MatchAll ]; Str s2 ] -> Comment [ s; s2 ]
        | _ ->
            Printf.printf
              "Token with regex %s cannot be converted into a bnfc comment!"
            @@ string_of_regex tok;
            raise @@ Failure "Unsupported"
      in
      List.map mk_comment_bnfc comments
    in
    let unique_mappings = collect_unique_results rest in
    let to_bnfc (regex, name) = Token { name; regex } in
    (comment_bnfc, List.map to_bnfc unique_mappings)

  let comments = comment_bnfc
  let tokens = keyword_bnfc @ regex_bnfc
  let reserved = reserved_decls
end
